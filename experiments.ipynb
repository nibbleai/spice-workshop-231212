{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/title.png\" width=\"800px\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Experiments\n",
    "\n",
    "In this notebook, we explore data and experiment iteratively.\n",
    "\n",
    "## Part 1 - Data Exploration\n",
    "\n",
    "2 datasets are used:\n",
    "- TLC NYC Taxi trips (2015) - [link](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "- NOAA Climate data of JFK airport, NYC (2015) - [link](https://www.ncei.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094789/detail)\n",
    "\n",
    "### TLC NYC Taxi trips\n",
    "Contains taxi trips, whose duration we seek to predict.\n",
    "<br><br>\n",
    "\n",
    "| Column name | Description |\n",
    "| :- | :- |\n",
    "| vendor_id | TPEP provider that provided the record |\n",
    "| pickup_datetime | The start date of the ride |\n",
    "| dropoff_datetime | The end date of the ride |\n",
    "| passenger_count | Number of passenger |\n",
    "| trip_distance | The distance in Mile of the ride |\n",
    "| pickup_longitude | The longitude of starting point of the ride |\n",
    "| pickup_latitude | The latitude of starting point of the ride |\n",
    "| rate_code | The rate code |\n",
    "| store_and_fwd_flag | Trip record held in vehicle memory before sending to the vendor |\n",
    "| dropoff_longitude | The longitude of end point of the ride |\n",
    "| dropoff_latitude | The longitude of end point of the ride |\n",
    "| payment_type | Type of payment |\n",
    "| fare_amount | Amount of the ride in dollars |\n",
    "\n",
    "More details on data schema on the [NYC TLC website](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "\n",
    "\n",
    "### NOAA Climate data of JFK airport, NYC\n",
    "Contains weather information.\n",
    "Most 'important' columns are:\n",
    "<br><br>\n",
    "\n",
    "| Column name | Description |\n",
    "| :- | :- |\n",
    "| TMAX | Maximum temperature |\n",
    "| TMIN | Minimum temperature |\n",
    "| PRCP | Precipitation |\n",
    "| SNOW | Snowfall |\n",
    "| SNWD | Snow depth |\n",
    "| ACMH | Average cloudiness midnight to midnight |\n",
    "| TSUN | Total sunshine for the period |\n",
    "| AWND | Average wind speed |\n",
    "\n",
    "Full data schema is available on the [NOAA website](https://www.ncei.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094789/detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging is disabled to avoid uncomfortable logs from third party libraries\n",
    "import logging\n",
    "\n",
    "logging.disable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_train_dataset\n",
    "\n",
    "data = get_train_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydata_profiling\n",
    "\n",
    "ydata_profiling.ProfileReport(data).to_widgets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_target\n",
    "\n",
    "target = get_target(data)\n",
    "target.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Naive modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.schemas import TaxiColumn\n",
    "from src.config import config\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    data.sort_values(TaxiColumn.PICKUP_TIME).index,\n",
    "    test_size=config.test_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_idx)} trips\")\n",
    "print(f\"Test size: {len(test_idx)} trips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_EXTRACT = [\n",
    "    TaxiColumn.VENDOR_ID,\n",
    "    TaxiColumn.PASSENGER_COUNT,\n",
    "    TaxiColumn.PICKUP_LON,\n",
    "    TaxiColumn.PICKUP_LAT,\n",
    "    TaxiColumn.DROPOFF_LON,\n",
    "    TaxiColumn.DROPOFF_LAT,\n",
    "]\n",
    "\n",
    "features = data.loc[:, COLS_TO_EXTRACT]\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_target = features.iloc[train_idx], target.iloc[train_idx]\n",
    "test_features, test_target = features.iloc[test_idx], target.iloc[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "model = RandomForestRegressor(random_state=RANDOM_STATE).fit(train_features, train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sorted_idx = model.feature_importances_.argsort()\n",
    "\n",
    "plt.barh(model.feature_names_in_[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "\n",
    "SCORING_METHODS = ('neg_mean_absolute_error', 'neg_mean_squared_error')\n",
    "N_SPLITS = 5\n",
    "\n",
    "model = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "splitter = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    model,\n",
    "    features,\n",
    "    target,\n",
    "    scoring=SCORING_METHODS,\n",
    "    cv=splitter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_scores).agg(['mean', 'std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/nibble.png\" width=\"300px\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
